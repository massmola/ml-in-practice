{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732cd282",
   "metadata": {},
   "source": [
    "# Assignment # 1\n",
    "\n",
    "## 1. Data Preprocessing\n",
    "\n",
    "Import the `titanic.csv` dataset.\n",
    "\n",
    "It contains data of the real Titanic passengers. Each row represents one person. The columns describe different attributes about the person including whether they survived (considered as the class label), their age, their passenger-class (Pclass), their sex, ther number of their relatives and the fare they paid. \n",
    "\n",
    "Execute the following tasks:\n",
    "- How many samples are in the dataset?\n",
    "- What are the types of the attributes?\n",
    "- Show the boxplots for the numeric attributes. Discuss the presence of outliers.\n",
    "- Remove the outliers (if present) for the numeric attributes by using the IQR method.\n",
    "- Apply normaxlization (minMax scaler) to the numeric attributes (excluding the class).\n",
    "- convert the Sex attribute in a numeric one: replace `male` with 0 and `female` with 1.\n",
    "- Select the data about the survived people vs not survived people. Is there imbalanced in the classes?\n",
    "- Plot the scatter plot for the numeric attributes divided per classes (people vs not survived).\n",
    "- Are the classes easly separable?\n",
    "- By inspecting the scatter plots, are ther important attributes that allow an easy separation of the classes?\n",
    "- Are there correlated features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a7528",
   "metadata": {},
   "source": [
    "## 2. Distance Measures Between Data and K-NN Classification\n",
    "\n",
    "Implement the `L1` and `L2` distances among the samples of the preprocessed `titanic.csv` dataset and perform a K-NNN classification. Look carefully at the feature and select the ones that are useful for computing a similarity. This task is similar to exercise 1 in Lab 2 but in this case you must avoid for loops.\n",
    "\n",
    "The exercise requires the following tasks:\n",
    "\n",
    "1. Remove from the dataset 5 samples of survived people and 5 of not survived ones and store in a Numpy array. These will be the test samples. The other part of the dataset is regarded as the training set.\n",
    "2. write a `L1_distance` function that performs the `L1` distance among the test samples and all the samples in the training set. The output will be a `10 x n` distance matrix `DM` (`n` is the total number of samples in the trainig set) where each cell `DM[i, j]` contains the distance between the test sample with index `i` and the training sample with index `j`. Avoid for loops by using Numpy broadcasting as explained in Lab 2 and in the online notes.\n",
    "3. Do the same of point 2 for `L2_distance`.\n",
    "4. Given an index `i` of a test sample, return the classes of the top 5 samples more similar to `i`. This can be achieved by using the [argpartition](https://numpy.org/doc/stable/reference/generated/numpy.argpartition.html) or the [argsort](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html) Numpy functions. Then, consider the class of `i` as the majority class in the 5 top samples.\n",
    "5. For each test sample `i` from 0 to 9, are the L1 and L2 functions able to return the same class of `i`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0432bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
